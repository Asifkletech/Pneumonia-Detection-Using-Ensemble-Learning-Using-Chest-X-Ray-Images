{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QU4vXVejhKw4"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import seaborn as sns\n",
        "import skimage\n",
        "from skimage import io, transform\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 30\n",
        "data_dir = \"/content/drive/MyDrive/chest_xray\"\n",
        "TEST = 'test'\n",
        "TRAIN = 'train'\n",
        "VAL = 'val'"
      ],
      "metadata": {
        "id": "6UhLh3ZthcGk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_transforms(phase):\n",
        "    if phase == TRAIN:\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "    elif phase == VAL:\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "    elif phase == TEST:\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "        ])\n",
        "    return transform"
      ],
      "metadata": {
        "id": "RqzOJjkzisSe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_with_transform(transform, device):\n",
        "    print(f\"Testing transform: {transform}\")\n",
        "    transform = transforms.Compose([\n",
        "        transform,\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), transform)\n",
        "                      for x in [TRAIN, VAL, TEST]}\n",
        "\n",
        "    dataloaders = {TRAIN: torch.utils.data.DataLoader(image_datasets[TRAIN], batch_size=4, shuffle=True),\n",
        "                   VAL: torch.utils.data.DataLoader(image_datasets[VAL], batch_size=1, shuffle=True),\n",
        "                   TEST: torch.utils.data.DataLoader(image_datasets[TEST], batch_size=1, shuffle=True)}\n",
        "\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL]}\n",
        "    classes = image_datasets[TRAIN].classes\n",
        "    class_names = image_datasets[TRAIN].classes\n",
        "\n",
        "    model_pre = models.vgg16(pretrained=True)\n",
        "    for param in model_pre.features.parameters():\n",
        "        param.required_grad = False\n",
        "\n",
        "    num_features = model_pre.classifier[6].in_features\n",
        "    features = list(model_pre.classifier.children())[:-1]\n",
        "    features.extend([nn.Linear(num_features, len(class_names))])\n",
        "    model_pre.classifier = nn.Sequential(*features)\n",
        "\n",
        "    model_pre = model_pre.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model_pre.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n",
        "    exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "DiMBUf6HizzF"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the parametric sweep for each transform\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "transforms_to_test = [\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    # Add more transforms here as needed\n",
        "]\n",
        "\n",
        "for transform in transforms_to_test:\n",
        "    run_with_transform(transform, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDTIOtHoi5uq",
        "outputId": "9de9329c-5d5e-4ecf-864a-2a70ffd8d4d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing transform: Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:04<00:00, 118MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing transform: CenterCrop(size=(224, 224))\n",
            "Testing transform: RandomHorizontalFlip(p=0.5)\n",
            "Testing transform: RandomRotation(degrees=[-30.0, 30.0], interpolation=nearest, expand=False, fill=0)\n",
            "Testing transform: ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.2, 0.2))\n",
            "Testing transform: RandomAffine(degrees=[0.0, 0.0], translate=(0.1, 0.1))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TRAIN = 'train'\n",
        "VAL = 'val'\n",
        "TEST = 'test'\n",
        "\n",
        "def data_transforms(phase, resize_size, crop_size, normalize_mean, normalize_std):\n",
        "    if phase == TRAIN or phase == VAL or phase == TEST:\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize(resize_size),\n",
        "            transforms.CenterCrop(crop_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(normalize_mean, normalize_std),\n",
        "        ])\n",
        "    else:\n",
        "        raise ValueError(\"Invalid phase\")\n",
        "\n",
        "    return transform\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# Define parameters for the sweep\n",
        "resize_sizes = [256, 512]  # Vary resize size\n",
        "crop_sizes = [224, 448]    # Vary crop size\n",
        "normalize_means = [[0.485, 0.456, 0.406], [0.5, 0.5, 0.5]]  # Vary mean for normalization\n",
        "normalize_stds = [[0.229, 0.224, 0.225], [0.1, 0.1, 0.1]]    # Vary std for normalization\n",
        "\n",
        "# Sweep through parameters\n",
        "for resize_size in resize_sizes:\n",
        "    for crop_size in crop_sizes:\n",
        "        for normalize_mean in normalize_means:\n",
        "            for normalize_std in normalize_stds:\n",
        "                transform = data_transforms(phase=TRAIN,\n",
        "                                             resize_size=resize_size,\n",
        "                                             crop_size=crop_size,\n",
        "                                             normalize_mean=normalize_mean,\n",
        "                                             normalize_std=normalize_std)\n",
        "                print(\"Resize Size:\", resize_size)\n",
        "                print(\"Crop Size:\", crop_size)\n",
        "                print(\"Normalize Mean:\", normalize_mean)\n",
        "                print(\"Normalize Std:\", normalize_std)\n",
        "                print(\"Transform:\", transform)\n",
        "                print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASmM_KmFX7rS",
        "outputId": "0a6be583-8625-46a3-c208-0806dfd4585f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n",
            "Resize Size: 256\n",
            "Crop Size: 224\n",
            "Normalize Mean: [0.485, 0.456, 0.406]\n",
            "Normalize Std: [0.229, 0.224, 0.225]\n",
            "Transform: Compose(\n",
            "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 256\n",
            "Crop Size: 224\n",
            "Normalize Mean: [0.485, 0.456, 0.406]\n",
            "Normalize Std: [0.1, 0.1, 0.1]\n",
            "Transform: Compose(\n",
            "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.1, 0.1, 0.1])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 256\n",
            "Crop Size: 224\n",
            "Normalize Mean: [0.5, 0.5, 0.5]\n",
            "Normalize Std: [0.229, 0.224, 0.225]\n",
            "Transform: Compose(\n",
            "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 256\n",
            "Crop Size: 224\n",
            "Normalize Mean: [0.5, 0.5, 0.5]\n",
            "Normalize Std: [0.1, 0.1, 0.1]\n",
            "Transform: Compose(\n",
            "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.1, 0.1, 0.1])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 256\n",
            "Crop Size: 448\n",
            "Normalize Mean: [0.485, 0.456, 0.406]\n",
            "Normalize Std: [0.229, 0.224, 0.225]\n",
            "Transform: Compose(\n",
            "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(448, 448))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 256\n",
            "Crop Size: 448\n",
            "Normalize Mean: [0.485, 0.456, 0.406]\n",
            "Normalize Std: [0.1, 0.1, 0.1]\n",
            "Transform: Compose(\n",
            "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(448, 448))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.1, 0.1, 0.1])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 256\n",
            "Crop Size: 448\n",
            "Normalize Mean: [0.5, 0.5, 0.5]\n",
            "Normalize Std: [0.229, 0.224, 0.225]\n",
            "Transform: Compose(\n",
            "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(448, 448))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 256\n",
            "Crop Size: 448\n",
            "Normalize Mean: [0.5, 0.5, 0.5]\n",
            "Normalize Std: [0.1, 0.1, 0.1]\n",
            "Transform: Compose(\n",
            "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(448, 448))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.1, 0.1, 0.1])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 512\n",
            "Crop Size: 224\n",
            "Normalize Mean: [0.485, 0.456, 0.406]\n",
            "Normalize Std: [0.229, 0.224, 0.225]\n",
            "Transform: Compose(\n",
            "    Resize(size=512, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 512\n",
            "Crop Size: 224\n",
            "Normalize Mean: [0.485, 0.456, 0.406]\n",
            "Normalize Std: [0.1, 0.1, 0.1]\n",
            "Transform: Compose(\n",
            "    Resize(size=512, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.1, 0.1, 0.1])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 512\n",
            "Crop Size: 224\n",
            "Normalize Mean: [0.5, 0.5, 0.5]\n",
            "Normalize Std: [0.229, 0.224, 0.225]\n",
            "Transform: Compose(\n",
            "    Resize(size=512, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 512\n",
            "Crop Size: 224\n",
            "Normalize Mean: [0.5, 0.5, 0.5]\n",
            "Normalize Std: [0.1, 0.1, 0.1]\n",
            "Transform: Compose(\n",
            "    Resize(size=512, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.1, 0.1, 0.1])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 512\n",
            "Crop Size: 448\n",
            "Normalize Mean: [0.485, 0.456, 0.406]\n",
            "Normalize Std: [0.229, 0.224, 0.225]\n",
            "Transform: Compose(\n",
            "    Resize(size=512, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(448, 448))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 512\n",
            "Crop Size: 448\n",
            "Normalize Mean: [0.485, 0.456, 0.406]\n",
            "Normalize Std: [0.1, 0.1, 0.1]\n",
            "Transform: Compose(\n",
            "    Resize(size=512, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(448, 448))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.1, 0.1, 0.1])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 512\n",
            "Crop Size: 448\n",
            "Normalize Mean: [0.5, 0.5, 0.5]\n",
            "Normalize Std: [0.229, 0.224, 0.225]\n",
            "Transform: Compose(\n",
            "    Resize(size=512, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(448, 448))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "\n",
            "\n",
            "Resize Size: 512\n",
            "Crop Size: 448\n",
            "Normalize Mean: [0.5, 0.5, 0.5]\n",
            "Normalize Std: [0.1, 0.1, 0.1]\n",
            "Transform: Compose(\n",
            "    Resize(size=512, interpolation=bilinear, max_size=None, antialias=warn)\n",
            "    CenterCrop(size=(448, 448))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.1, 0.1, 0.1])\n",
            ")\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}